# CAMPFIRE: Downstream evaluations of channel agnostic vision transformer
Repository for code used to run experiments in "Out-of-distribution evaluations of channel agnostic masked autoencoders in fluorescence microscopy"

### 1. How to use code to pretrain, and evaluate channel agnostic model 

To generate the results of the experiments in our manuscript, we provide the code to run downstream evaluations of our model. Although we do not provide the code to train **Campfire**, by providing this code, it is possible, given a directory to the embeddings of data from the JUMP-CP dataset, to compare a model to ours using the same downstream criteria. 

#### 1.1 Generating training, validation, and held-out splits. 

Run the following command 
```
python create_controls.py -c controls_config.yaml
```
This will generate a .csv file for each of the TARGET2 and COMPOUND plates in Source 3. These .csv files are plate maps, such that each cell will describe the position on the 384-well plate, the compound with which it was stimulated, and the split to which it has been assigned. Using the provided config will generate the same set of data splits used to train **Campfire**. 

#### 1.2. Model pretraining and inference 
We do not provide code to run model pretraining. To keep comparisons with **Campfire** consistent, models should be evaluated using the test and held-out splits defined in the controls. If researchers wish to compare models trained on identical datasets, **Campfire** was pretrained using all wells assigned to the training set in the control csvs generated by the above. 

The downstream evaluations specified in the next sections assume that a model is pretrained. All that is necessary to run the below, are the control csvs, and an additional csv containing the single cell embeddings of the model for all wells in the TARGET2 plates. This csv file, should contain columns for: the ROW and COLUMN of the well, the PLATE BARCODE of the plate from which the well is derived, and for a model with embedding dimension D should have D columns named EMBEDDING_LAYER_NAME_0,...,EMBEDDING_LAYER_NAME_D-1. 


#### 1.3. Given a set of embeddings, run linear probing, predicting 1-of-9 controls 

In our manuscript, we evaluate models for fluorscence microscopy by training a linear layer with single cell embeddings to predict 1-of-9 controls. 
By running `python runners/run_linear_pipeline.py` will trigger a pipleline, that via a config file, set within `runners/run_linear_pipeline.py`, takes a .csv file containing all single cell embeddings for TARGET2 plates, samples single cell embeddings from each well, assigns them to data splits, and then trains several linear layers using different subsets of the training set. The output of this will be the performance metrics for the in-distribution test set and out-of-distribution test set, for the model specified by the config file. 

#### 1.4. Given a set of embeddings, run linear probing, predicting 1-of-60 held-out compounds  
To evaluate models when dealing with images of cells subject to out-of-distribution compounds, we train a linear layer with single cell embeddings to predict 1-of-60 compounds held-out of model pretraining (as specified in the control csv files generated earlier). Within `runners/run_held_out_pipeline.py` set the config file for the model under evaluation (i.e **Campfire**, DinoViT-S8, etc). After setting config file, run `python runners/run_held_out_pipeline.py` to trigger a pipeline that will take single cell embeddings, sample 30 embeddings from each well in the TARGET2 plates, and train 5 linear layers, using 5 subsets of the training data via cross-fold validation. The output of this will be the performance metrics for the in-distribution test set and out-of-distribution test set, for the model specified by the config file. 


### 2. Generating results from manuscript 

Here we provide details of which config files and code were used to generate each figure and table within our manuscript.


#### 2.1. Results for Table 3.1
To generate results shown in Table 3.1, use the following:
```
python runners/run_linear_pipeline.py 
```
with the config file set to 
1. `configs/models/dino_vits8.yaml`
2. `configs/models/dino_vitl14.yaml`
3. `configs/models/campfire.yaml`  
and 
```
python runners/run_held_out_linear_pipeline.py 
```
with the config file set to 
1. `configs/models/held_out/dino_vits8.yaml`
2. `configs/models/held_out/dino_vitl14.yaml`
3. `configs/models/held_out/campfire.yaml`  

#### 2.2. Results for Figure 3.1
To generate results shown in Figure 3.1, use the following:
```
python runners/run_linear_pipeline.py 
```
with the config file set to 
1. `configs/channel_integration/nucleus.yaml` 
2. `configs/channel_integration/actin.yaml` 
3. `configs/channel_integration/mitochondria.yaml` 
4. `configs/channel_integration/nucleus_actin.yaml`
5. `configs/channel_integration/nucleus_mitochondria.yaml`
6. `configs/models/campfire.yaml`
```
python runners/run_held_out_linear_pipeline.py 
```
with the config file set to 
1. `configs/channel_integration/held_out/nucleus.yaml` 
2. `configs/channel_integration/held_out/actin.yaml` 
3. `configs/channel_integration/held_out/mitochondria.yaml` 
4. `configs/channel_integration/held_out/nucleus_actin.yaml`
5. `configs/channel_integration/held_out/nucleus_mitochondria.yaml`
6. `configs/models/campfire.yaml`.

Following this, to generate the figures, run 
`python plot_channel_integration.py -c $CONFIG`  
with CONFIG set to 
1. `configs/channel_integration/channel_integration.yaml` 
2. `configs/channel_integration/held_out/channel_integration.yaml`.

#### 2.3. Results for Table 3.2
To generate results shown in Table 3.2, use the following:
```
python runners/run_linear_pipeline.py 
```
with the config file set to 
1. `configs/batch_generalisation/1_plates.yaml` 
2. `configs/batch_generalisation/5_plates.yaml` 
3. `configs/batch_generalisation/10_plates.yaml`   
and
```
python runners/run_held_out_linear_pipeline.py 
```
with the config file set to 
1. `configs/batch_generalisation/held_out/1_plates.yaml` 
2. `configs/batch_generalisation/held_out/5_plates.yaml` 
3. `configs/batch_generalisation/held_out/10_plates.yaml` 

#### 2.4. Results for Table 3.3
To generate results shown in Table 3.3, use the following:
```
python runners/run_linear_pipeline.py 
```
with the config file set to 
1. `configs/unseen_channel/fvit_s3.yaml` 
2. `configs/unseen_channel/dino_vits8.yaml`  
and
```
python runners/run_held_out_linear_pipeline.py 
```
with the config file set to 
1. `configs/unseen_channel/held_out/fvit_s3.yaml` 
2. `configs/unseen_channel/held_out/dino_vits8.yaml`.

#### 2.5. Results for Figure 3.2
To generate results shown in Figure 3.2, use the following:
```
python modelling/macrophage_embeddings.py -c $CONFIG
```
with $CONFIG set to 
1. `configs/finetuning/config_fvit_head.yaml` 
2. `configs/finetuning/config_dino_head.yaml`.

#### 2.6. Results for Figure 3.3
To generate results shown in Figure 3.3, use the following:
```
python modelling/macrophage_zprime.py -c $CONFIG
```
with $CONFIG set to 
1. `configs/finetuning/config_fvit_head.yaml` 
2. `configs/finetuning/config_dino_head.yaml`.